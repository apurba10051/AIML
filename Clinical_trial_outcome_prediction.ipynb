{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apurba10051/AIML/blob/main/Clinical_trial_outcome_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM6AQxx7LmAB"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tnsJXwItQHQI"
      },
      "outputs": [],
      "source": [
        "!pip install transformers sentence-transformers pandas scikit-learn xgboost requests torch numpy shap lime imbalanced-learn transformers numpy optuna streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNOoOMhgQNK0"
      },
      "outputs": [],
      "source": [
        "# Data Manipulation and Analysis:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Deep Learning (PyTorch and Transformers):\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModel\n",
        "\n",
        "# Sentence Embeddings:\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Model Selection:\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "\n",
        "# Preprocessing:\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "# Models:\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Hyperparameter Tuning:\n",
        "import optuna\n",
        "\n",
        "# Metrics:\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix, precision_recall_curve, auc, precision_recall_fscore_support\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Pipelines:\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# SHAP & LIME (Model Interpretability):\n",
        "import shap\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "from lime import lime_text\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "# Visualization:\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Utilities:\n",
        "import requests\n",
        "import re\n",
        "import traceback\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# IPython Display:\n",
        "from IPython.display import display\n",
        "\n",
        "# Import necessary libraries for file upload\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA_1kUb_7cYp"
      },
      "outputs": [],
      "source": [
        "def fetch_data(base_url, params):\n",
        "    response = requests.get(base_url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        print(\"API Response Data:\", data)  # Print the whole API response to verify the structure\n",
        "        studies = data.get('studies', [])\n",
        "        return studies\n",
        "    else:\n",
        "        print(\"Failed to fetch data. Response:\", response.text)\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZUUa7JNJFNm"
      },
      "outputs": [],
      "source": [
        "def parse_study_data(studies):\n",
        "    data_list = []\n",
        "\n",
        "    for study in studies:\n",
        "        try:\n",
        "            protocol_section = study['protocolSection']\n",
        "            identification_module = protocol_section['identificationModule']\n",
        "            status_module = protocol_section['statusModule']\n",
        "            eligibility_module = protocol_section['eligibilityModule']\n",
        "            design_module = protocol_section['designModule']\n",
        "            conditions_module = protocol_section['conditionsModule']\n",
        "            interventions_module = protocol_section.get('armsInterventionsModule', {'interventions': []})\n",
        "            outcomes_module = protocol_section.get('outcomesModule', {})\n",
        "            locations_module = protocol_section.get('contactsLocationsModule', {}).get('locations', [])\n",
        "            condition_browse_module = study.get('derivedSection', {}).get('conditionBrowseModule', {}).get('meshes', [])\n",
        "\n",
        "            nct_id = identification_module.get('nctId', 'Unknown')\n",
        "            overall_status = status_module.get('overallStatus', 'Unknown')\n",
        "            lead_sponsor = protocol_section.get('sponsorCollaboratorsModule', {}).get('leadSponsor', {}).get('name', 'Apurba Sponsor')\n",
        "            start_date = status_module.get('startDateStruct', {}).get('date', '2020-01')\n",
        "            end_date = status_module.get('completionDateStruct', {}).get('date', '2020-01')\n",
        "            enrollment = design_module.get('enrollmentInfo', {}).get('count', 0)\n",
        "            eligibility_criteria = eligibility_module.get('eligibilityCriteria', '')\n",
        "            #inclusion_summary, exclusion_summary = parse_criteria(eligibility_criteria)\n",
        "            inclusion_summary, exclusion_summary, min_age, max_age = parse_criteria(eligibility_criteria)\n",
        "            conditions_keywords = conditions_module.get('keywords', [])\n",
        "            interventions = ', '.join([intervention['name'] for intervention in interventions_module.get('interventions', [])])\n",
        "            browse_keywords = [mesh['term'] for mesh in condition_browse_module]\n",
        "            all_keywords = set(conditions_keywords + browse_keywords)\n",
        "            all_keywords_string = ', '.join(all_keywords)\n",
        "            primary_outcomes = outcomes_module.get('primaryOutcomes', [])\n",
        "            primary_outcome_summary = \"; \".join([outcome['measure'] for outcome in primary_outcomes])\n",
        "            secondary_outcomes = outcomes_module.get('secondaryOutcomes', [])\n",
        "            secondary_outcome_summary = \"; \".join([outcome['measure'] for outcome in secondary_outcomes])\n",
        "\n",
        "            # Extract Intervention Type\n",
        "            intervention_types = []\n",
        "            for intervention in interventions_module.get('interventions', []):\n",
        "                intervention_type = intervention.get('interventionType', 'Unknown')\n",
        "                intervention_types.append(intervention_type)\n",
        "            intervention_types_string = ', '.join(intervention_types)\n",
        "\n",
        "\n",
        "            # Aggregate location information\n",
        "            cities = []\n",
        "            states = []\n",
        "            countries = []\n",
        "            addresses = []\n",
        "            for location in locations_module:\n",
        "                city = location.get('city', 'No City')\n",
        "                state = location.get('state', 'No State')\n",
        "                country = location.get('country', 'No Country')\n",
        "                address = location.get('facility', 'No Address')\n",
        "                cities.append(city)\n",
        "                states.append(state)\n",
        "                countries.append(country)\n",
        "                addresses.append(address)\n",
        "\n",
        "            # Combine location information into a single string\n",
        "            city_string = ', '.join(cities)\n",
        "            state_string = ', '.join(states)\n",
        "            country_string = ', '.join(countries)\n",
        "            address_string = ', '.join(addresses)\n",
        "\n",
        "            study_data = {\n",
        "                'NCT ID': nct_id,\n",
        "                'Overall Status': overall_status,\n",
        "                'Address': address_string,\n",
        "                'Start Date': start_date,\n",
        "                'End Date': end_date,\n",
        "                'Enrollment': enrollment,\n",
        "                'Study Type': design_module.get('studyType', 'Unknown'),\n",
        "                'Brief Title': identification_module.get('briefTitle', 'Unknown'),\n",
        "                'Description': summarize_text(protocol_section['descriptionModule'].get('briefSummary', 'No description provided')),\n",
        "                'Conditions': ', '.join(conditions_module.get('conditions', ['No conditions listed'])),\n",
        "                'Interventions': interventions,\n",
        "                'Phases': ', '.join([phase if phase not in ['Unknown', 'NA', '', None] else 'Phase0' for phase in design_module.get('phases', ['Phase0'])]),\n",
        "                'Inclusion Criteria Summary': inclusion_summary,\n",
        "                'Exclusion Criteria Summary': exclusion_summary,\n",
        "                'Lead Sponsor': lead_sponsor,\n",
        "                'Keywords': all_keywords_string,\n",
        "                'Primary Outcome': primary_outcome_summary,\n",
        "                'Secondary Outcome': secondary_outcome_summary,\n",
        "                'City': city_string,\n",
        "                'State': state_string,\n",
        "                'Country': country_string,\n",
        "                'Intervention Type': intervention_types_string\n",
        "            }\n",
        "\n",
        "            data_list.append(study_data)\n",
        "\n",
        "        except KeyError as e:\n",
        "            print(f\"Key error: {e} in study {nct_id}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error: {e} in study {nct_id if 'nct_id' in locals() else 'Unknown'}\")\n",
        "\n",
        "    print(f\"Total studies processed: {len(data_list)}\")\n",
        "    return data_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DafbzYXMH8eL"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "BASE_URL = 'https://clinicaltrials.gov/api/v2/studies'\n",
        "PARAMS = {\n",
        "    'query.titles': 'Diabetes',\n",
        "    'pageSize': 300\n",
        "}\n",
        "\n",
        "# Load t5 tokenizer and model\n",
        "t5_tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "t5_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IwafF0ef0kjw"
      },
      "outputs": [],
      "source": [
        "def summarize_text(text):\n",
        "    inputs = t5_tokenizer(text, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = t5_model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    bullet_points = re.sub(r'(?<!\\n)\\n(?!\\n)', '\\n* ', '* ' + summary)  # Add bullet points\n",
        "    return bullet_points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmcgybtw0kjx"
      },
      "outputs": [],
      "source": [
        "def parse_criteria(text):\n",
        "    try:\n",
        "        inclusion_search = re.search(r'Inclusion Criteria:(.*?)Exclusion Criteria:', text, re.DOTALL)\n",
        "        exclusion_search = re.search(r'Exclusion Criteria:(.*)', text, re.DOTALL)\n",
        "\n",
        "        inclusion_text = inclusion_search.group(1).strip() if inclusion_search else ''\n",
        "        exclusion_summary = summarize_text(exclusion_search.group(1).strip()) if exclusion_search else 'No exclusion criteria provided.'\n",
        "        inclusion_summary = summarize_text(inclusion_text) if inclusion_search else 'No inclusion criteria provided.'\n",
        "\n",
        "        return inclusion_summary, exclusion_summary\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing criteria: {e}\")\n",
        "        return \"Error in parsing\", \"Error in parsing\", 0, 99"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaa6Sg3rTIB3"
      },
      "outputs": [],
      "source": [
        "# Call fetch_data and parse_study_data to get the data\n",
        "studies = fetch_data(BASE_URL, PARAMS) # Call fetch_data to get studies\n",
        "data_list = parse_study_data(studies)  # Call parse_study_data to process studies\n",
        "\n",
        "#create df from data_list\n",
        "df = pd.DataFrame(data_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTQolgFPG8y7"
      },
      "source": [
        "## --- Import CSV from Local Drive in Colab-------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_b8SLhhaG5nK"
      },
      "outputs": [],
      "source": [
        "# Step 1: Upload the CSV file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 2: Read the uploaded CSV file into a DataFrame\n",
        "# Assuming the uploaded file is a CSV file\n",
        "for filename in uploaded.keys():\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(\"DataFrame created from the uploaded CSV file:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqBdpsz3aLgp"
      },
      "outputs": [],
      "source": [
        "# Optionally, save the DataFrame to a CSV file\n",
        "df.to_csv(\"clinical_trials_data_intake.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giC-MhDRM7J6"
      },
      "source": [
        "## Check Missing Values Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEghAK4-Gg7E"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Reloading the CSV file for analysis\n",
        "clinical_trials_data = pd.read_csv(\"/content/clinical_trials_data_intake (1).csv\")\n",
        "\n",
        "# Checking for missing values in each column\n",
        "missing_values = clinical_trials_data.isnull().sum()\n",
        "\n",
        "# Calculating the percentage of missing values\n",
        "missing_percentage = (missing_values / len(clinical_trials_data)) * 100\n",
        "missing_summary = pd.DataFrame({\n",
        "    \"Column\": clinical_trials_data.columns,\n",
        "    \"Missing Values (%)\": missing_percentage\n",
        "}).sort_values(by=\"Missing Values (%)\", ascending=False)\n",
        "\n",
        "# Getting unique values in key columns for consistency checks\n",
        "unique_values_summary = {\n",
        "    \"Overall Status\": clinical_trials_data[\"Overall Status\"].unique(),\n",
        "    \"Phases\": clinical_trials_data[\"Phases\"].unique(),\n",
        "    \"Study Type\": clinical_trials_data[\"Study Type\"].unique(),\n",
        "}\n",
        "\n",
        "# Visualizing missing data using a heatmap\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(clinical_trials_data.isnull(), cbar=False, cmap=\"viridis\")\n",
        "plt.title(\"Missing Data Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "# Display missing value summary and unique values\n",
        "missing_summary, unique_values_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-NWYXULa9oV"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rINrYoKXebg7"
      },
      "outputs": [],
      "source": [
        "# Print unique values of the Overall Status column\n",
        "unique_status_values = df['Overall Status'].unique()\n",
        "print(\"Unique values in 'Overall Status':\")\n",
        "print(unique_status_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndRqwpXmNN2Z"
      },
      "source": [
        "## Distribution of Clinical Trial By Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JS8Q_R1PNHPS"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "clinical_trials_data['Phases'].value_counts().plot(kind='bar', color='skyblue', edgecolor='black')\n",
        "plt.title('Distribution of Clinical Trials by Phase', fontsize=16)\n",
        "plt.xlabel('Phase', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "plt.xticks(rotation=45, fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f96jIO-VbF6Q"
      },
      "source": [
        "## Funnel Chart for Recruitment Phases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIXTygBbbIsM"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "phase_counts = clinical_trials_data['Phases'].value_counts()\n",
        "\n",
        "fig = go.Figure(go.Funnel(\n",
        "    y=phase_counts.index,\n",
        "    x=phase_counts.values,\n",
        "    textinfo=\"value+percent initial\",\n",
        "    marker={\"color\": [\"blue\", \"green\", \"yellow\", \"red\"]},\n",
        "))\n",
        "\n",
        "fig.update_layout(title='Funnel Chart of Clinical Trial Phases')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tMW2rfeNXUS"
      },
      "source": [
        "## Proportion of Trials by Overall Status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5GJSWYgNSxm"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 8))\n",
        "clinical_trials_data['Overall Status'].value_counts().plot(\n",
        "    kind='pie', autopct='%1.1f%%', startangle=90, cmap='tab10', textprops={'fontsize': 8}\n",
        ")\n",
        "plt.title('Proportion of Trials by Overall Status', fontsize=8)\n",
        "plt.ylabel('')  # Remove y-axis label for better aesthetics\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z9vUkvgVFpu"
      },
      "source": [
        "## With Smote and Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IHK4-TntTxp"
      },
      "source": [
        "## -----BLOCK 1: FEATURE ENGINEERING-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMmXUfiTLgwH"
      },
      "outputs": [],
      "source": [
        "# --- New Duration Calculation ---\n",
        "# Convert to datetime and calculate duration\n",
        "df['Start Date'] = pd.to_datetime(df['Start Date'], errors='coerce')\n",
        "df['End Date'] = pd.to_datetime(df['End Date'], errors='coerce')\n",
        "df['duration_days'] = (df['End Date'] - df['Start Date']).dt.days\n",
        "\n",
        "# Handle missing duration\n",
        "median_duration = df['duration_days'].median()\n",
        "df['duration_days'] = df['duration_days'].fillna(median_duration)\n",
        "\n",
        "# --- Enhanced Text Processing ---\n",
        "# Add Title to text features\n",
        "df['combined_text'] = df['Brief Title'].fillna('') + ' ' + \\\n",
        "                     df['Description'].fillna('') + ' ' + \\\n",
        "                     df['Keywords'].fillna('') + ' ' + \\\n",
        "                     df['Inclusion Criteria Summary'].fillna('') + ' ' + \\\n",
        "                     df['Primary Outcome'].fillna('') + ' ' + \\\n",
        "                     df['Secondary Outcome'].fillna('') + ' ' + \\\n",
        "                     df['Country'].fillna('')\n",
        "\n",
        "# --- Rest remains similar ---\n",
        "label_encoders = {}\n",
        "for col in ['Study Type', 'Phases', 'Lead Sponsor']:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "y_original = df['Overall Status'].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGvL8m5BTKW1"
      },
      "source": [
        "## BLOCK 1.1 = Embedding / PCA  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "497_3SnVMvID"
      },
      "outputs": [],
      "source": [
        "## BLOCK 1.1 = Embedding / PCA\n",
        "# Get ClinicalBERT embeddings\n",
        "MODEL_NAME = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "clinical_bert_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "clinical_bert_model = AutoModel.from_pretrained(MODEL_NAME)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "clinical_bert_model = clinical_bert_model.to(device)\n",
        "\n",
        "def get_clinical_embeddings(texts, batch_size=8):\n",
        "    \"\"\"Generate clinical context-aware embeddings\"\"\"\n",
        "    clinical_bert_model.eval()\n",
        "    embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        inputs = clinical_bert_tokenizer(\n",
        "            batch,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = clinical_bert_model(**inputs)\n",
        "\n",
        "        embeddings.append(outputs.last_hidden_state[:, 0, :].cpu().numpy())\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "text_embeddings = get_clinical_embeddings(df['combined_text'].tolist())\n",
        "\n",
        "# Use PCA instead of TruncatedSVD\n",
        "pca = PCA(n_components=50)  # Reduce to 50 components\n",
        "text_reduced = pca.fit_transform(text_embeddings)\n",
        "\n",
        "# Create feature names for PCA components\n",
        "text_columns = [f'pca_{i}' for i in range(50)]\n",
        "\n",
        "# Combine all features\n",
        "X = pd.concat([\n",
        "    df[['duration_days', 'Enrollment', 'Study Type', 'Phases']],\n",
        "    pd.DataFrame(text_reduced, columns=text_columns)\n",
        "], axis=1)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "X.columns = X.columns.astype(str)\n",
        "\n",
        "# Scale numerical features\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()\n",
        "X[['Enrollment', 'duration_days']] = scaler.fit_transform(X[['Enrollment', 'duration_days']])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_embeddings)"
      ],
      "metadata": {
        "id": "d7nZdMduK6ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN6aMwhFJivI"
      },
      "source": [
        "## ----BLOCK 2: TARGET SETUP-------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlR0z2NNSWxi"
      },
      "outputs": [],
      "source": [
        "# Use original target values for splitting\n",
        "y = y_original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhGebEJgJyf8"
      },
      "source": [
        "## -------BLOCK 3: CLASS BALANCING-------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yr7BLXLQRsJd"
      },
      "outputs": [],
      "source": [
        "# --- BLOCK 3: CLASS BALANCING & DATA PREPARATION ---\n",
        "# Keep original data intact\n",
        "X_full = X.copy()\n",
        "y_full = y.copy()\n",
        "\n",
        "# Identify valid classes in FULL dataset\n",
        "class_counts = y_full.value_counts()\n",
        "min_samples = max(5, class_counts.min())\n",
        "valid_classes = class_counts[class_counts >= min_samples].index\n",
        "\n",
        "# Split FIRST to preserve training set integrity\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_full,\n",
        "    y_full,\n",
        "    test_size=0.2,\n",
        "    stratify=y_full,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Now filter training data (preserve test data integrity)\n",
        "train_valid_mask = y_train.isin(valid_classes) # return true/false\n",
        "X_train = X_train[train_valid_mask]\n",
        "y_train = y_train[train_valid_mask]\n",
        "\n",
        "# Reset index of X_train and X_test\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)\n",
        "y_train = y_train.reset_index(drop=True)\n",
        "y_test = y_test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8bJ1QhDKLi3"
      },
      "source": [
        "##----------- BLOCK 4: RESAMPLING & TARGET ENCODING---------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- BLOCK 4: RESAMPLING & ENCODING ---\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Calculate class balance AFTER filtering\n",
        "train_counts = y_train.value_counts()\n",
        "\n",
        "# Apply SMOTE only if needed\n",
        "if len(train_counts) > 1:  # Check for multiple classes\n",
        "    safe_k = max(1, min(3, train_counts.min() - 1))  # Ensure k_neighbors ≥1,  prevent k_neighbors from being 0, which is not allowed in SMOTE.\n",
        "    resampler = SMOTE(\n",
        "        k_neighbors=safe_k,\n",
        "        random_state=42\n",
        "    )\n",
        "    X_res, y_res = resampler.fit_resample(X_train, y_train)\n",
        "else:\n",
        "    X_res, y_res = X_train.copy(), y_train.copy()\n",
        "\n",
        "# Encode AFTER resampling\n",
        "target_encoder = LabelEncoder()\n",
        "y_res_encoded = target_encoder.fit_transform(y_res)\n",
        "y_test_encoded = target_encoder.transform(y_test[y_test.isin(valid_classes)])"
      ],
      "metadata": {
        "id": "2jNkYTu-rrnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---  Block 4.1: Original vs Resampled Class Distribution ---"
      ],
      "metadata": {
        "id": "BgyXgfpGr-v4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---  Block 4.1: Resampled Class Distribution ---\n",
        "# Create comparison between original training data and resampled data\n",
        "original_counts = y_train.value_counts().reset_index()\n",
        "original_counts.columns = ['Class', 'Count']\n",
        "original_counts['Dataset'] = 'Original (Train)'\n",
        "\n",
        "resampled_counts = pd.Series(y_res).value_counts().reset_index()\n",
        "resampled_counts.columns = ['Class', 'Count']\n",
        "resampled_counts['Dataset'] = 'Resampled (Train)'\n",
        "\n",
        "combined = pd.concat([original_counts, resampled_counts])\n",
        "\n",
        "# Plot with annotations\n",
        "plt.figure(figsize=(14, 7))\n",
        "ax = sns.barplot(x='Class', y='Count', hue='Dataset', data=combined,\n",
        "                palette=['#1f77b4', '#ff7f0e'])\n",
        "plt.title('Class Distribution: Original vs SMOTE-Resampled Training Data\\n'\n",
        "         f\"(Total original samples: {len(y_train)}, Resampled: {len(y_res)})\",\n",
        "         pad=20)\n",
        "plt.xlabel('Class Label', labelpad=12)\n",
        "plt.ylabel('Number of Samples', labelpad=12)\n",
        "\n",
        "# Add exact count labels\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{int(p.get_height())}',\n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='baseline',\n",
        "                xytext=(0, 5), textcoords='offset points')\n",
        "\n",
        "plt.legend(title='Dataset Version', loc='upper right')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YQoUQM5cnHjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_KCMid9KhL2"
      },
      "source": [
        "##-------BLOCK 5: MODEL TRAINING-------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_zxDKBjI_uR"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-4, 10.0),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-4, 10.0),\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': len(np.unique(y_res_encoded)), # Number of classes after encoding\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(X_res, y_res_encoded)\n",
        "\n",
        "    # Filter the test set to keep only valid classes that were present during training:\n",
        "    # Create a boolean mask for the test set:\n",
        "    test_mask = y_test.isin(valid_classes) # Filter y_test by valid classes\n",
        "\n",
        "    # Apply the mask to filter both features (X_test) and target (y_test):\n",
        "    X_test_filtered = X_test[test_mask]\n",
        "    y_test_filtered = y_test[test_mask]\n",
        "\n",
        "    # Encode the filtered test set:\n",
        "    y_test_filtered_encoded = target_encoder.transform(y_test_filtered)\n",
        "\n",
        "    # Now, perform prediction on the filtered test set:\n",
        "    y_pred_encoded = model.predict(X_test_filtered)\n",
        "\n",
        "    # Finally, calculate the accuracy score with the filtered data:\n",
        "    return accuracy_score(y_test_filtered_encoded, y_pred_encoded)\n",
        "\n",
        "# Create and optimize the study (rest of the code remains the same)\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50, timeout=300)\n",
        "\n",
        "# Final model training\n",
        "best_params = study.best_params\n",
        "best_model = XGBClassifier(\n",
        "    **best_params,\n",
        "    objective='multi:softprob',\n",
        "    num_class=len(np.unique(y_res))\n",
        ")\n",
        "best_model.fit(X_res, y_res_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCcBCTIJKbLl"
      },
      "source": [
        "## ------------ BLOCK 6: PREDICTION ------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z64mRrJpKXym"
      },
      "outputs": [],
      "source": [
        "X_test.columns = X_test.columns.astype(str)\n",
        "# Predict using encoded target space\n",
        "y_pred_encoded = best_model.predict(X_test)\n",
        "y_proba = best_model.predict_proba(X_test)\n",
        "\n",
        "# Decode predictions using TARGET encoder\n",
        "y_pred_decoded = target_encoder.inverse_transform(y_pred_encoded)\n",
        "\n",
        "# Create unified status map\n",
        "final_status_map = {i: lbl for i, lbl in enumerate(target_encoder.classes_)}\n",
        "final_status_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD-_e6kR-6Gq"
      },
      "source": [
        "## Inverse Transform - Phase, Study Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByIWuByIm9bM"
      },
      "outputs": [],
      "source": [
        "# Instead of directly using inverse_transform, create a mapping\n",
        "# from the encoded values to the original values\n",
        "study_type_mapping = dict(zip(label_encoders['Study Type'].classes_,\n",
        "                               label_encoders['Study Type'].transform(label_encoders['Study Type'].classes_)))\n",
        "\n",
        "# Reverse the mapping to get original values from encoded values\n",
        "reverse_study_type_mapping = {v: k for k, v in study_type_mapping.items()}\n",
        "\n",
        "# Apply the reverse mapping to the 'Study Type' column\n",
        "df['Study Type'] = df['Study Type'].map(reverse_study_type_mapping).fillna(df['Study Type'])\n",
        "# Create a mapping for 'Phases' similar to 'Study Type'\n",
        "phases_mapping = dict(zip(label_encoders['Phases'].classes_,\n",
        "                             label_encoders['Phases'].transform(label_encoders['Phases'].classes_)))\n",
        "\n",
        "# Reverse the mapping for 'Phases'\n",
        "reverse_phases_mapping = {v: k for k, v in phases_mapping.items()}\n",
        "\n",
        "# Apply the reverse mapping to the 'Phases' column\n",
        "df['Phases'] = df['Phases'].map(reverse_phases_mapping).fillna(df['Phases'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyaiXzcwIBc6"
      },
      "source": [
        "##  -----Hide----BLOCK 7: Add predictions to original data--------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giyhXRLhIBc6"
      },
      "outputs": [],
      "source": [
        "# --- BLOCK 7: Add predictions to original data ---\n",
        "import numpy as np\n",
        "\n",
        "# Get original filtered DataFrame (from Block 3)\n",
        "final_df = df.copy()  # This already contains only valid classes after Block 3 filtering\n",
        "\n",
        "# 1. Add TEST SET predictions -------------------------------------------------\n",
        "# Get test set indices relative to original filtered data\n",
        "test_mask = final_df.index.isin(X_test.index)  # X_test retains original filtered indices\n",
        "test_proba = best_model.predict_proba(X_test)\n",
        "final_df.loc[test_mask, 'Predicted Status'] = target_encoder.inverse_transform(best_model.predict(X_test))\n",
        "final_df.loc[test_mask, 'Prediction Confidence'] = np.max(test_proba, axis=1)\n",
        "\n",
        "# 2. Add TRAINING SET predictions ----------------------------------------------\n",
        "# Map resampled predictions to original training indices\n",
        "# Instead of using X_train.index, use the indices of the original training data\n",
        "# before resampling:\n",
        "train_proba = best_model.predict_proba(X_res[:len(X_train)])  # First N original samples\n",
        "final_df.loc[X_train.index, 'Predicted Status'] = target_encoder.inverse_transform(best_model.predict(X_res[:len(X_train)]))\n",
        "final_df.loc[X_train.index, 'Prediction Confidence'] = np.max(train_proba, axis=1)\n",
        "\n",
        "\n",
        "# 3. Cleanup and validation ---------------------------------------------------\n",
        "# Convert confidence to percentage\n",
        "final_df['Prediction Confidence'] = final_df['Prediction Confidence'].round(4)\n",
        "\n",
        "# Verify no overlapping indices (Fixed)\n",
        "# Use the original indices of the test set instead of X_test.index\n",
        "original_test_indices = final_df.index[test_mask]\n",
        "#assert final_df.loc[test_mask & final_df.index.isin(X_train.index)].empty, \"Train/test index overlap!\"\n",
        "\n",
        "print(\"\\nFinal Prediction Summary:\")\n",
        "print(final_df[['NCT ID', 'Start Date', 'End Date', 'Overall Status', 'Predicted Status', 'Prediction Confidence']].head(10))\n",
        "\n",
        "# Calculate accuracy only on test set\n",
        "test_acc = accuracy_score(\n",
        "    y_true=final_df.loc[test_mask, 'Overall Status'],\n",
        "    y_pred=final_df.loc[test_mask, 'Predicted Status']\n",
        ")\n",
        "print(f\"\\nTest Set Accuracy: {test_acc:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_rhWwsUOdLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CgtQTN-U7gGW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzWoZCQI0Bex"
      },
      "source": [
        "## NEW BLOCK 7.1 : Feature importance check (for alternate logic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gi7Zy-VK0BId"
      },
      "outputs": [],
      "source": [
        "# Feature importance check\n",
        "importances = pd.Series(best_model.feature_importances_, index=X.columns)\n",
        "print(\"\\nTop 50 Features:\")\n",
        "print(importances.sort_values(ascending=False).head(50))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO5mWix3K00b"
      },
      "source": [
        "## ---------BLOCK 8:Display Results & Save Predictions in CSV-------------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- BLOCK 8: Display Results & Save Predictions in CSV ---\n",
        "\n",
        "# Inverse Transform - Phase, Study Type\n",
        "# Instead of directly using inverse_transform, create a mapping\n",
        "# from the encoded values to the original values\n",
        "study_type_mapping = dict(zip(label_encoders['Study Type'].classes_,\n",
        "                               label_encoders['Study Type'].transform(label_encoders['Study Type'].classes_)))\n",
        "\n",
        "# Reverse the mapping to get original values from encoded values\n",
        "reverse_study_type_mapping = {v: k for k, v in study_type_mapping.items()}\n",
        "\n",
        "# Apply the reverse mapping to the 'Study Type' column\n",
        "final_df['Study Type'] = final_df['Study Type'].map(reverse_study_type_mapping).fillna(final_df['Study Type'])\n",
        "# Create a mapping for 'Phases' similar to 'Study Type'\n",
        "phases_mapping = dict(zip(label_encoders['Phases'].classes_,\n",
        "                             label_encoders['Phases'].transform(label_encoders['Phases'].classes_)))\n",
        "\n",
        "# Reverse the mapping for 'Phases'\n",
        "reverse_phases_mapping = {v: k for k, v in phases_mapping.items()}\n",
        "\n",
        "# Apply the reverse mapping to the 'Phases' column\n",
        "final_df['Phases'] = final_df['Phases'].map(reverse_phases_mapping).fillna(final_df['Phases'])\n",
        "\n",
        "\n",
        "# Display Results\n",
        "# Include all columns from final_df (which incorporates data_list)\n",
        "display(final_df.head())\n",
        "final_df.to_csv('clinical_trial_predictions.csv', index=False)\n",
        "print(\"✅ Results saved to 'clinical_trial_predictions.csv'\")\n",
        "print(f\"✅ Final DataFrame Row Count: {len(final_df)}\")"
      ],
      "metadata": {
        "id": "ejiIYqVPPse1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaKIRk4EqCwW"
      },
      "source": [
        "## ------ BLOCK 9: Model Evaluation ------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgXMN9AWMmC0"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "from sklearn.metrics import precision_recall_fscore_support, recall_score, precision_score, roc_auc_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "# Filter X_test and y_test to ensure consistent samples for evaluation:\n",
        "test_mask = y_test.isin(valid_classes)\n",
        "X_test_filtered = X_test[test_mask]\n",
        "y_test_filtered = y_test[test_mask]\n",
        "\n",
        "# Encode the filtered target variable:\n",
        "y_test_encoded = target_encoder.transform(y_test_filtered)\n",
        "\n",
        "# Generate predictions on the filtered test set:\n",
        "y_pred_encoded = best_model.predict(X_test_filtered)\n",
        "y_proba = best_model.predict_proba(X_test_filtered)\n",
        "\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_test_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "recall = recall_score(y_test_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "f1 = f1_score(y_test_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "auc_score = roc_auc_score(y_test_encoded, y_proba, multi_class='ovo', average='macro')\n",
        "conf_matrix = confusion_matrix(y_test_encoded, y_pred_encoded)\n",
        "class_report = classification_report(y_test_encoded, y_pred_encoded, target_names=target_encoder.classes_)\n",
        "\n",
        "# Precision-Recall AUC (modified for encoded labels)\n",
        "precision_pr, recall_pr, _ = precision_recall_curve(y_test_encoded, y_proba[:, 1], pos_label=1)\n",
        "pr_auc = auc(recall_pr, precision_pr)\n",
        "\n",
        "# Print the results (structure unchanged)\n",
        "print(f'Accuracy: {accuracy:.3f}')\n",
        "print(f'Precision: {precision:.3f}')\n",
        "print(f'Recall: {recall:.3f}')\n",
        "print(f'F1 Score: {f1:.3f}')\n",
        "print(f'ROC AUC: {auc_score:.3f}')\n",
        "print(f'PR-AUC: {pr_auc:.3f}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('Classification Report:')\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8q3EMPTAIjE"
      },
      "source": [
        "## ------ BLOCK 10: Confusion Matrix ------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QTRhyu3SGvF"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay  # Import ConfusionMatrixDisplay instead\n",
        "\n",
        "# Generate predictions (if not already done)\n",
        "# Use y_test_encoded and y_pred_encoded for consistency\n",
        "y_pred_encoded = best_model.predict(X_test)\n",
        "\n",
        "# Assuming target_encoder was used for encoding\n",
        "y_pred_decoded = target_encoder.inverse_transform(y_pred_encoded) # Decode predictions to match y_test type\n",
        "\n",
        "# Plot Confusion Matrix using ConfusionMatrixDisplay\n",
        "# Use original (decoded) labels for y_pred\n",
        "cm_display = ConfusionMatrixDisplay.from_predictions(y_test, y_pred_decoded, cmap='Blues')\n",
        "cm_display.ax_.set_title('Confusion Matrix')  # Set title\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epPmsGvuANWv"
      },
      "source": [
        "## ------ BLOCK 11: ROC-AUC Curve ------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LLbpuzeTFzr"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'y_test' contains your original target labels (strings)\n",
        "# and 'best_model' is your trained XGBClassifier\n",
        "\n",
        "# Binarize the output - for multi-class ROC AUC calculation\n",
        "y_test_bin = label_binarize(y_test, classes=target_encoder.classes_)\n",
        "n_classes = y_test_bin.shape[1]  # Number of classes\n",
        "\n",
        "# Get predicted probabilities\n",
        "y_pred_proba = best_model.predict_proba(X_test)\n",
        "y_pred_proba = y_pred_proba[:, :n_classes]  # Select probabilities for the filtered classes\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area (overall performance)\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_pred_proba.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure(figsize=(10, 8))\n",
        "lw = 2  # Line width\n",
        "\n",
        "# Plot micro-average ROC curve (overall)\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "# Plot ROC curves for individual classes\n",
        "colors = ['aqua', 'darkorange', 'cornflowerblue', 'green']  # Add more colors if needed\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(target_encoder.classes_[i], roc_auc[i]))  # Use target_encoder for original labels\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)  # Diagonal line\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Multi-class ROC AUC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combine the PR-AUC and ROC-AUC plots into a single figure for better comparison"
      ],
      "metadata": {
        "id": "kRllnY7irPJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "\n",
        "# Assuming y_test_encoded and y_pred_proba are already defined\n",
        "\n",
        "# Binarize the output for multi-class ROC AUC calculation\n",
        "y_test_bin = label_binarize(y_test, classes=target_encoder.classes_)\n",
        "n_classes = y_test_bin.shape[1]\n",
        "\n",
        "# Get predicted probabilities for all classes\n",
        "y_pred_proba = best_model.predict_proba(X_test)\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area (overall performance)\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_pred_proba.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "# Plotting\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# ROC Curve Plot (micro-average)\n",
        "ax1.plot(fpr[\"micro\"], tpr[\"micro\"], color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc[\"micro\"])\n",
        "ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "ax1.set_xlim([0.0, 1.0])\n",
        "ax1.set_ylim([0.0, 1.05])\n",
        "ax1.set_xlabel('False Positive Rate')\n",
        "ax1.set_ylabel('True Positive Rate')\n",
        "ax1.set_title('Receiver Operating Characteristic (Micro-Average)')\n",
        "ax1.legend(loc=\"lower right\")\n",
        "\n",
        "# Precision-Recall Curve Plot (micro-average)\n",
        "# For PR curve, we'll use the micro-averaged precision and recall\n",
        "precision, recall, _ = precision_recall_curve(y_test_bin.ravel(), y_pred_proba.ravel())\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "ax2.plot(recall, precision, color='blue', lw=2, label='PR curve (area = %0.2f)' % pr_auc)\n",
        "ax2.set_xlim([0.0, 1.0])\n",
        "ax2.set_ylim([0.0, 1.05])\n",
        "ax2.set_xlabel('Recall')\n",
        "ax2.set_ylabel('Precision')  # Added ylabel\n",
        "ax2.set_title('Precision-Recall Curve (Micro-Average)')  # Added title\n",
        "ax2.legend(loc=\"lower right\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2Eevgtpxqy-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOU30VR6LPi2"
      },
      "source": [
        "## ------ BLOCK 12:  SHAP CODE------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRLM_BtjSZ0o"
      },
      "outputs": [],
      "source": [
        "# ====== MODEL INTERPRETATION BLOCK ======\n",
        "# ------ SHAP Analysis ------\n",
        "print(\"\\nRunning SHAP analysis...\")\n",
        "\n",
        "# SHAP Global Explanations\n",
        "shap_explainer = shap.TreeExplainer(best_model)\n",
        "shap_values = shap_explainer.shap_values(X_train)\n",
        "\n",
        "# Reshape SHAP values if multi-class\n",
        "if len(shap_values.shape) == 3:  # Check if multi-class\n",
        "    shap_values = shap_values.sum(axis=2)  # Sum across classes\n",
        "\n",
        "# Ensure feature_names is a simple list\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "shap.summary_plot(shap_values, X_train, feature_names=feature_names, plot_type=\"dot\")\n",
        "plt.title(\"Global Feature Importance (SHAP)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTUoFFWlowlA"
      },
      "outputs": [],
      "source": [
        "for feature in feature_names:\n",
        "    shap.dependence_plot(feature, shap_values, X_train, interaction_index=\"auto\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYQcu7eWAaL2"
      },
      "source": [
        "## ------ BLOCK 13: LIME Analysis------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfrWcWCcNwnD"
      },
      "outputs": [],
      "source": [
        "# ------ LIME Analysis ------\n",
        "print(\"\\nRunning LIME analysis...\")\n",
        "\n",
        "# LIME Setup\n",
        "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_train.values,  # Convert to NumPy array\n",
        "    feature_names=X.columns.tolist(),\n",
        "    class_names=target_encoder.classes_,  # Use target_encoder instead of label_encoders\n",
        "    mode='classification',\n",
        "    verbose=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# LIME Explanation\n",
        "sample_idx = np.random.randint(0, len(X_test))\n",
        "exp = lime_explainer.explain_instance(\n",
        "    X_test.iloc[sample_idx].values, # Access the row using .iloc and convert to NumPy array\n",
        "    best_model.predict_proba,\n",
        "    num_features=10,\n",
        "    top_labels=3\n",
        ")\n",
        "\n",
        "# LIME Visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "exp.as_pyplot_figure()\n",
        "plt.title(f\"LIME Explanation for Sample {sample_idx}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twVKZTfxVHJh"
      },
      "outputs": [],
      "source": [
        "  # Display Results\n",
        "  display(final_df.head())\n",
        "  df.to_csv('clinical_trial_predictions.csv', index=False)\n",
        "  print(\"✅ Results saved to 'clinical_trial_prediction.csv'\")\n",
        "  print(f\"✅ Final DataFrame Row Count: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvRnILztrpVu"
      },
      "source": [
        "## -------------- Block 15: pipeline saving code ----------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tXofKy_SvYU"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Assuming PCA was used instead of SVD\n",
        "n_pca_components = pca.n_components\n",
        "\n",
        "# Construct feature names (including PCA components)\n",
        "feature_names = [\n",
        "    'duration_days',\n",
        "    'Enrollment',\n",
        "    'Study Type',\n",
        "    'Phases'\n",
        "] + [f'pca_{i}' for i in range(n_pca_components)]\n",
        "\n",
        "# Create the pipeline dictionary\n",
        "pipeline = {\n",
        "    'model': best_model,\n",
        "    'clinical_bert_tokenizer': clinical_bert_tokenizer,\n",
        "    'clinical_bert_model': clinical_bert_model,\n",
        "    'pca': pca,\n",
        "    'label_encoders': label_encoders,\n",
        "    'target_encoder': target_encoder,\n",
        "    'feature_names': feature_names,\n",
        "    'scaler': scaler, #add scaler\n",
        "    'imputer': imputer #add imputer\n",
        "}\n",
        "\n",
        "# Save the pipeline\n",
        "joblib.dump(pipeline, \"clinical_trial_predictor.pkl\")\n",
        "print(\"✅ Pipeline saved with all components!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m_EeWINUbL2"
      },
      "source": [
        "## --------BLOCK 16: Streamlit UI Code-----"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steamlit code block w/ UI Validation - 24 feb 2024"
      ],
      "metadata": {
        "id": "bhcL-w4kd9cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Medical context validation with enhanced term recognition\n",
        "class MedicalTermRecognizer:\n",
        "    def __init__(self):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "        self.model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "\n",
        "        # Expanded disease patterns\n",
        "        self.disease_patterns = re.compile(\n",
        "            r'\\b(heart attack|myocardial infarction|covid(-19)?|coronavirus|diabetes|'\n",
        "            r'stroke|sepsis|pneumonia|arrhythmia|hypertension|asthma|arthritis|'\n",
        "            r'leukemia|melanoma|alzheimer\\'?s|parkinson\\'?s|tuberculosis|'\n",
        "            r'epilepsy|migraine|osteoporosis)\\b|'\n",
        "            r'\\b([A-Z][a-z]+ (disease|syndrome|disorder))\\b',\n",
        "            re.IGNORECASE\n",
        "        )\n",
        "\n",
        "        # Broad medical context references\n",
        "        self.reference_texts = [\n",
        "            \"Clinical trial investigating disease treatment outcomes\",\n",
        "            \"Patient study on cardiovascular health interventions\",\n",
        "            \"Randomized controlled trial of infectious disease therapies\",\n",
        "            \"Phase III study of chronic condition management\",\n",
        "            \"Multicenter research protocol for emergency medical treatments\"\n",
        "        ]\n",
        "\n",
        "    def get_embeddings(self, text):\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\",\n",
        "                              padding=True, truncation=True,\n",
        "                              max_length=256)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "        return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "    def validate_medical_context(self, text, threshold=0.55):\n",
        "        \"\"\"Hybrid validation with enhanced medical term recognition\"\"\"\n",
        "        # Direct disease term matching\n",
        "        if self.disease_patterns.search(text):\n",
        "            return True, \"Recognized medical terms\"\n",
        "\n",
        "        # Semantic similarity check\n",
        "        text_emb = self.get_embeddings(text)\n",
        "        ref_embs = self.get_embeddings(self.reference_texts)\n",
        "        similarity = np.max(cosine_similarity(text_emb, ref_embs))\n",
        "\n",
        "        if similarity > threshold:\n",
        "            return True, f\"Medical context detected (confidence: {similarity:.2f})\"\n",
        "        return False, \"No clear medical context identified\"\n",
        "\n",
        "# Load prediction pipeline\n",
        "try:\n",
        "    pipeline = joblib.load('clinical_trial_predictor.pkl')\n",
        "    model = pipeline['model']\n",
        "    clinical_bert_tokenizer = pipeline['clinical_bert_tokenizer']\n",
        "    clinical_bert_model = pipeline['clinical_bert_model']\n",
        "    pca = pipeline['pca']\n",
        "    label_encoders = pipeline['label_encoders']\n",
        "    target_encoder = pipeline['target_encoder']\n",
        "    feature_names = pipeline['feature_names']\n",
        "    scaler = pipeline['scaler']\n",
        "    imputer = pipeline['imputer']\n",
        "except Exception as e:\n",
        "    st.error(f\"Pipeline loading failed: {str(e)}\")\n",
        "    st.stop()\n",
        "\n",
        "# Initialize components\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "clinical_bert_model = clinical_bert_model.to(device)\n",
        "validator = MedicalTermRecognizer()\n",
        "\n",
        "# Streamlit UI\n",
        "st.title('Clinical Trial Status Predictor')\n",
        "\n",
        "with st.form(\"trial_form\"):\n",
        "    # Input fields\n",
        "    brief_title = st.text_input(\"Brief Title*\")\n",
        "    description = st.text_area(\"Study Description*\")\n",
        "    keywords = st.text_input(\"Keywords (comma-separated)*\")\n",
        "    inclusion = st.text_area(\"Inclusion Criteria Summary*\")\n",
        "    country = st.text_input(\"Country\")\n",
        "\n",
        "    start_date = st.date_input(\"Start Date*\")\n",
        "    end_date = st.date_input(\"End Date*\")\n",
        "\n",
        "    enrollment = st.number_input(\"Enrollment*\", min_value=0)\n",
        "\n",
        "    study_type = st.selectbox(\"Study Type*\",\n",
        "                            options=label_encoders['Study Type'].classes_)\n",
        "    phases = st.selectbox(\"Phase*\",\n",
        "                        options=label_encoders['Phases'].classes_)\n",
        "\n",
        "    submitted = st.form_submit_button(\"Predict\")\n",
        "    st.markdown(\"*Required fields\")\n",
        "\n",
        "if submitted:\n",
        "    try:\n",
        "        # Validate medical context\n",
        "        validation_results = {\n",
        "            \"Title\": brief_title,\n",
        "            \"Description\": description,\n",
        "            \"Inclusion Criteria\": inclusion\n",
        "        }\n",
        "\n",
        "        for field, text in validation_results.items():\n",
        "            is_valid, message = validator.validate_medical_context(text)\n",
        "            if not is_valid:\n",
        "                matches = validator.disease_patterns.findall(text)\n",
        "                detected_terms = \", \".join({m[0].lower() for m in matches if m[0]})\n",
        "                raise ValueError(\n",
        "                    f\"{field} validation failed: {message}\\n\"\n",
        "                    f\"Detected terms: {detected_terms or 'None'}\"\n",
        "                )\n",
        "\n",
        "        # Feature engineering\n",
        "        duration_days = (end_date - start_date).days\n",
        "        combined_text = f\"{brief_title} {description} {keywords} {inclusion} {country}\"\n",
        "\n",
        "        # Generate embeddings\n",
        "        inputs = clinical_bert_tokenizer(\n",
        "            combined_text,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = clinical_bert_model(**inputs)\n",
        "\n",
        "        text_embeddings = outputs.last_hidden_state[:,0,:].cpu().numpy()\n",
        "        text_reduced = pca.transform(text_embeddings)\n",
        "\n",
        "        # Prepare features\n",
        "        feature_values = [\n",
        "            duration_days,\n",
        "            enrollment,\n",
        "            label_encoders['Study Type'].transform([study_type])[0],\n",
        "            label_encoders['Phases'].transform([phases])[0],\n",
        "            *text_reduced[0].tolist()\n",
        "        ]\n",
        "\n",
        "        features = pd.DataFrame([feature_values], columns=feature_names)\n",
        "        features = pd.DataFrame(imputer.transform(features), columns=features.columns)\n",
        "        features[['Enrollment', 'duration_days']] = scaler.transform(\n",
        "            features[['Enrollment', 'duration_days']]\n",
        "        )\n",
        "\n",
        "        # Prediction\n",
        "        proba = model.predict_proba(features)\n",
        "        prediction = model.predict(features)\n",
        "        confidence = np.max(proba)\n",
        "        status = target_encoder.inverse_transform(prediction)[0]\n",
        "\n",
        "        # Display results\n",
        "        st.subheader(\"Prediction Results\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            st.metric(\"Predicted Status\", status)\n",
        "\n",
        "        with col2:\n",
        "            # Determine color based on confidence\n",
        "            if confidence > 0.7:\n",
        "                color = \"green\"\n",
        "            elif confidence > 0.5:\n",
        "                color = \"orange\"\n",
        "            else:\n",
        "                color = \"red\"\n",
        "\n",
        "            # Create custom HTML for colored confidence display\n",
        "            confidence_html = f\"\"\"\n",
        "                <div style=\"color: {color}; font-size: 2rem; font-weight: bold;\">\n",
        "                    {confidence:.1%}\n",
        "                </div>\n",
        "                <div style=\"color: gray; font-size: 0.8rem;\">\n",
        "                    Confidence Score\n",
        "                </div>\n",
        "            \"\"\"\n",
        "            st.markdown(confidence_html, unsafe_allow_html=True)\n",
        "\n",
        "        if confidence < 0.6:\n",
        "            st.warning(\"Low confidence prediction - verify input quality\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(str(e))\n",
        "        st.stop()"
      ],
      "metadata": {
        "id": "xxlHT_kadnlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPmoiZE_UfSh"
      },
      "source": [
        "## --------------- Run streamlit on ngrok-------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7NeTU5SSgkV"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit pyngrok --quiet\n",
        "from pyngrok import ngrok\n",
        "!ngrok authtoken \"2slOT6TvLHh9iiLyVuV9NMkNBsk_2v5bf7FjG4vA29dyGC45X\"  # 👈 Replace with your actual key\n",
        "\n",
        "# Run Streamlit\n",
        "!streamlit run app.py &>/dev/null &\n",
        "\n",
        "# Setup ngrok tunnel\n",
        "public_url = ngrok.connect(addr='8501')  # Change to 'localhost:8501' or '127.0.0.1:8501'\n",
        "print(\"Clinical Trial Predictor Streamlit app is available at:\", public_url.public_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Requirements.txt file"
      ],
      "metadata": {
        "id": "udhNOsgXWtvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "WCefcB9uWhWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2JUOFWnb_oW"
      },
      "source": [
        "## ---------------- Disconnect ngrok Tunnels-------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pfdnn-2rbs_V"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set your ngrok authtoken\n",
        "ngrok.set_auth_token(\"2slOT6TvLHh9iiLyVuV9NMkNBsk_2v5bf7FjG4vA29dyGC45X\")  # Replace with your actual authtoken\n",
        "\n",
        "# List all active tunnels\n",
        "tunnels = ngrok.get_tunnels()\n",
        "\n",
        "# Disconnect each tunnel\n",
        "for tunnel in tunnels:\n",
        "    ngrok.disconnect(tunnel.public_url)\n",
        "    print(f\"Disconnected tunnel: {tunnel.public_url}\")\n",
        "\n",
        "print(\"All tunnels have been disconnected.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## --- BLOCK 17 - Visualization Block-----"
      ],
      "metadata": {
        "id": "EuzYpE_YWAkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization 1: Feature Importance Plot"
      ],
      "metadata": {
        "id": "eQc4ZHPg28jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization 1: Feature Importance Plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'best_model' is your trained XGBoost model\n",
        "importances = best_model.feature_importances_\n",
        "feature_names = X_train.columns  # Get feature names from X_train\n",
        "\n",
        "# Sort feature importances in descending order\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Create a bar plot of feature importances\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
        "plt.xticks(range(X_train.shape[1]), feature_names[indices], rotation=90)\n",
        "plt.xlim([-1, X_train.shape[1]])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GxpO0W4mWFQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization 2: Distribution of Predicted Probabilities"
      ],
      "metadata": {
        "id": "EAhk5TcU3AuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# ... (previous code for model training and prediction) ...\n",
        "\n",
        "y_pred_decoded = target_encoder.inverse_transform(best_model.predict(X_test))\n",
        "\n",
        "proba_df = pd.DataFrame(y_proba, columns=target_encoder.classes_)\n",
        "proba_df['Predicted Status'] = y_pred_decoded\n",
        "\n",
        "# Melt the DataFrame to create a long-form structure for plotting\n",
        "melted_proba_df = pd.melt(proba_df, id_vars=['Predicted Status'],\n",
        "                         value_vars=target_encoder.classes_,\n",
        "                         var_name='Class', value_name='Probability')\n",
        "\n",
        "# Plot the distribution of probabilities for each class using box plot\n",
        "plt.figure(figsize=(12, 8))  # Adjust figure size as needed\n",
        "sns.boxplot(x='Predicted Status', y='Probability', hue='Class', data=melted_proba_df)\n",
        "plt.title(\"Distribution of Predicted Probabilities for All Classes\")\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels if needed\n",
        "plt.tight_layout()\n",
        "plt.legend(title='Class', bbox_to_anchor=(1.05, 1), loc='upper left')  # Adjust legend position\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fD97IEM1WHyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization 3: Original Class Distribution"
      ],
      "metadata": {
        "id": "M80P8Y_7sgTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization 5: Original Class Distribution\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'y' contains the target variable\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x=y)\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JTQA2sGvWPcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nib1xN4b5Iy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ✅ HINT Benchmark Performance\n",
        "HINT_performance = {\n",
        "    'ROC AUC': 0.800,\n",
        "    'F1': 0.65,\n",
        "    'PR-AUC': 0.735,\n",
        "}\n",
        "\n",
        "# ✅ Our Model Performance (Replace these with actual metrics from evaluate_model)\n",
        "our_model_performance = {\n",
        "        'ROC AUC': 0.70,  # Use default values if key not found\n",
        "        'F1': 0.59,\n",
        "        'PR-AUC': 0.74,\n",
        "}\n",
        "\n",
        "# ✅ Plotting Performance Comparison\n",
        "def plot_performance_comparison(HINT_performance, our_model_performance):\n",
        "    labels = list(HINT_performance.keys())\n",
        "    hint_scores = list(HINT_performance.values())\n",
        "    model_scores = list(our_model_performance.values())\n",
        "\n",
        "    x = np.arange(len(labels))  # label locations\n",
        "    width = 0.35  # bar width\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    rects1 = ax.bar(x - width/2, hint_scores, width, label='HINT Benchmark')\n",
        "    rects2 = ax.bar(x + width/2, model_scores, width, label='Our Model')\n",
        "\n",
        "    # Add labels and title\n",
        "    ax.set_ylabel('Scores')\n",
        "    ax.set_xlabel('Performance Metrics')\n",
        "    ax.set_title('Comparison of Model Performance with HINT Benchmark')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.legend()\n",
        "\n",
        "    # Add text annotations\n",
        "    for rect in rects1 + rects2:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.3f}',\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "    # Show Plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ✅ Call the Plotting Function\n",
        "plot_performance_comparison(HINT_performance, our_model_performance)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IyaiXzcwIBc6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}